{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Model Development & Training\n",
    "\n",
    "**Objective:** Design and train a deep learning model that predicts both drum onsets and velocities from mel spectrograms.\n",
    "\n",
    "This notebook implements our drum transcription neural network architecture, loss functions, and training pipeline. The model has dual heads for both onset detection and velocity prediction, allowing it to capture not just when a drum is hit but also how hard it's played."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup\n",
    "\n",
    "Loading required libraries for model development, training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "# For reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(\"../data\")\n",
    "PROCESSED_DATA_DIR = DATA_DIR / \"processed\"\n",
    "MODEL_SAVE_DIR = Path(\"../models\")\n",
    "MODEL_SAVE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Drum mapping (same as in previous notebooks)\n",
    "GM_DRUM_MAPPING = {\n",
    "        36: \"Kick\",\n",
    "        38: \"Snare\",\n",
    "        42: \"HiHat\",\n",
    "        47: \"Tom\",\n",
    "        49: \"Crash\",\n",
    "        51: \"Ride\"\n",
    "    }\n",
    "\n",
    "# Drum types constants\n",
    "MAIN_DRUMS = list(GM_DRUM_MAPPING.keys())\n",
    "MAIN_DRUM_NAMES = list(GM_DRUM_MAPPING.values())\n",
    "N_DRUMS = len(MAIN_DRUMS)\n",
    "\n",
    "# Configure plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Dataset and DataLoader\n",
    "\n",
    "Loading our preprocessed training examples (.npz files) and setting up the PyTorch data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrumTranscriptionDataset(Dataset):\n",
    "    \"\"\"Dataset for loading preprocessed drum transcription examples.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, split=\"train\"):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "        \n",
    "        Args:\n",
    "            data_dir: Directory containing the processed data\n",
    "            split: Which dataset split to use ('train', 'validation', or 'test')\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir) / split\n",
    "        self.file_list = list(self.data_dir.glob(\"*.npz\"))\n",
    "        \n",
    "        if len(self.file_list) == 0:\n",
    "            raise ValueError(f\"No .npz files found in {self.data_dir}\")\n",
    "            \n",
    "        print(f\"Found {len(self.file_list)} examples in {split} set\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load the NPZ file\n",
    "        data = np.load(self.file_list[idx])\n",
    "        \n",
    "        # Extract features and targets\n",
    "        mel_spec = data[\"mel_spec\"].astype(np.float32)  # [n_mels, n_frames]\n",
    "        onset_target = data[\"onset_target\"].astype(np.float32)  # [n_drums, n_frames]\n",
    "        velocity_target = data[\"velocity_target\"].astype(np.float32)  # [n_drums, n_frames]\n",
    "        \n",
    "        # Convert to tensors\n",
    "        mel_spec = torch.from_numpy(mel_spec)\n",
    "        onset_target = torch.from_numpy(onset_target) \n",
    "        velocity_target = torch.from_numpy(velocity_target)\n",
    "        \n",
    "        return {\n",
    "            \"input\": mel_spec,             # [n_mels, n_frames]\n",
    "            \"onset_target\": onset_target,  # [n_drums, n_frames]\n",
    "            \"velocity_target\": velocity_target,  # [n_drums, n_frames]\n",
    "            \"file_path\": str(self.file_list[idx])\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle variable-length sequences.\n",
    "    Pads sequences to the maximum length in the batch.\n",
    "    \"\"\"\n",
    "    # Get max sequence length in this batch\n",
    "    max_frames = max(item[\"input\"].shape[1] for item in batch)\n",
    "    \n",
    "    # Initialize tensors for batched data\n",
    "    batch_size = len(batch)\n",
    "    n_mels = batch[0][\"input\"].shape[0]\n",
    "    n_drums = batch[0][\"onset_target\"].shape[0]\n",
    "    \n",
    "    # Create padded tensors\n",
    "    inputs = torch.zeros((batch_size, n_mels, max_frames))\n",
    "    onset_targets = torch.zeros((batch_size, n_drums, max_frames))\n",
    "    velocity_targets = torch.zeros((batch_size, n_drums, max_frames))\n",
    "    file_paths = []\n",
    "    \n",
    "    # Fill in the data\n",
    "    for i, item in enumerate(batch):\n",
    "        frames = item[\"input\"].shape[1]\n",
    "        inputs[i, :, :frames] = item[\"input\"]\n",
    "        onset_targets[i, :, :frames] = item[\"onset_target\"]\n",
    "        velocity_targets[i, :, :frames] = item[\"velocity_target\"]\n",
    "        file_paths.append(item[\"file_path\"])\n",
    "    \n",
    "    return {\n",
    "        \"input\": inputs,\n",
    "        \"onset_target\": onset_targets,\n",
    "        \"velocity_target\": velocity_targets,\n",
    "        \"file_paths\": file_paths\n",
    "    }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = DrumTranscriptionDataset(PROCESSED_DATA_DIR, split=\"train\")\n",
    "val_dataset = DrumTranscriptionDataset(PROCESSED_DATA_DIR, split=\"validation\")\n",
    "test_dataset = DrumTranscriptionDataset(PROCESSED_DATA_DIR, split=\"test\")\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Inspect a Batch\n",
    "\n",
    "Let's examine a batch of data to understand the input and target formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from the training loader\n",
    "for batch in train_loader:\n",
    "    inputs = batch[\"input\"]\n",
    "    onset_targets = batch[\"onset_target\"]\n",
    "    velocity_targets = batch[\"velocity_target\"]\n",
    "    \n",
    "    print(f\"Input shape: {inputs.shape}\")  # [batch_size, n_mels, n_frames]\n",
    "    print(f\"Onset target shape: {onset_targets.shape}\")  # [batch_size, n_drums, n_frames]\n",
    "    print(f\"Velocity target shape: {velocity_targets.shape}\")  # [batch_size, n_drums, n_frames]\n",
    "    \n",
    "    # Plot one example\n",
    "    idx = 0  # First example in batch\n",
    "    plt.figure(figsize=(15, 9))\n",
    "    \n",
    "    # Plot mel spectrogram\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.imshow(inputs[idx].numpy(), aspect='auto', origin='lower', cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.title('Mel Spectrogram')\n",
    "    plt.ylabel('Mel Frequency Bin')\n",
    "    \n",
    "    # Plot onset targets\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.imshow(onset_targets[idx].numpy(), aspect='auto', origin='lower', cmap='Reds')\n",
    "    plt.colorbar()\n",
    "    plt.title('Drum Onsets')\n",
    "    plt.yticks(np.arange(N_DRUMS), MAIN_DRUM_NAMES)\n",
    "    \n",
    "    # Plot velocity targets\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.imshow(velocity_targets[idx].numpy(), aspect='auto', origin='lower', cmap='Blues')\n",
    "    plt.colorbar()\n",
    "    plt.title('Drum Velocities (Normalized 0-1)')\n",
    "    plt.yticks(np.arange(N_DRUMS), MAIN_DRUM_NAMES)\n",
    "    plt.xlabel('Time Frames')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Just examine one batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Model Architecture\n",
    "\n",
    "Create our drum transcription model based on a CNN architecture with dual output heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Convolutional block with batch normalization and ReLU activation.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class DrumTranscriptionModel(nn.Module):\n",
    "    \"\"\"CNN model for drum transcription with dual output heads.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_mels=229, n_drums=6, use_lstm=True):\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "        \n",
    "        Args:\n",
    "            n_mels: Number of mel frequency bands in input\n",
    "            n_drums: Number of drum types to detect\n",
    "            use_lstm: Whether to use LSTM layers for temporal modeling\n",
    "        \"\"\"\n",
    "        super(DrumTranscriptionModel, self).__init__()\n",
    "        self.n_mels = n_mels\n",
    "        self.n_drums = n_drums\n",
    "        self.use_lstm = use_lstm\n",
    "        \n",
    "        # Feature extraction: convolutional layers\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            # Layer 1: [B, 1, n_mels, T] -> [B, 32, n_mels//2, T]\n",
    "            ConvBlock(1, 32),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),  # Frequency pooling\n",
    "            \n",
    "            # Layer 2: [B, 32, n_mels//2, T] -> [B, 64, n_mels//4, T]\n",
    "            ConvBlock(32, 64),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),  # Frequency pooling\n",
    "            \n",
    "            # Layer 3: [B, 64, n_mels//4, T] -> [B, 128, n_mels//8, T]\n",
    "            ConvBlock(64, 128),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),  # Frequency pooling\n",
    "            \n",
    "            # Layer 4: [B, 128, n_mels//8, T] -> [B, 128, n_mels//16, T]\n",
    "            ConvBlock(128, 128),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))   # Frequency pooling\n",
    "        )\n",
    "        \n",
    "        # Calculate feature dimensions after CNN\n",
    "        self.cnn_output_dim = 128 * (n_mels // 16)\n",
    "        \n",
    "        # Optional: Bi-directional LSTM layer for temporal modeling\n",
    "        if self.use_lstm:\n",
    "            self.lstm = nn.LSTM(\n",
    "                input_size=self.cnn_output_dim,\n",
    "                hidden_size=256,\n",
    "                num_layers=1,\n",
    "                batch_first=True,\n",
    "                bidirectional=True\n",
    "            )\n",
    "            feature_dim = 512  # bidirectional LSTM output\n",
    "        else:\n",
    "            feature_dim = self.cnn_output_dim\n",
    "            \n",
    "        # Onset detection head\n",
    "        self.onset_head = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, n_drums),\n",
    "            nn.Sigmoid()  # Binary classification for each drum\n",
    "        )\n",
    "        \n",
    "        # Velocity prediction head\n",
    "        self.velocity_head = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, n_drums),\n",
    "            # No activation - regression task\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape [batch_size, n_mels, n_frames]\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (onset_predictions, velocity_predictions)\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Add channel dimension for CNN input [B, 1, n_mels, T]\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # Pass through CNN stack\n",
    "        x = self.conv_stack(x)\n",
    "        \n",
    "        # Reshape for RNN/Linear: [batch_size, time_steps, features]\n",
    "        x = x.permute(0, 3, 1, 2)  # [B, T, C, F]\n",
    "        x = x.reshape(batch_size, x.shape[1], -1)  # [B, T, C*F]\n",
    "        \n",
    "        # Optional: Pass through LSTM for temporal modeling\n",
    "        if self.use_lstm:\n",
    "            x, _ = self.lstm(x)  # [B, T, 2*hidden_size]\n",
    "        \n",
    "        # Apply the output heads\n",
    "        onset_pred = self.onset_head(x)  # [B, T, n_drums]\n",
    "        velocity_pred = self.velocity_head(x)  # [B, T, n_drums]\n",
    "        \n",
    "        # Reshape to match target format [B, n_drums, T]\n",
    "        onset_pred = onset_pred.transpose(1, 2)\n",
    "        velocity_pred = velocity_pred.transpose(1, 2)\n",
    "        \n",
    "        return onset_pred, velocity_pred\n",
    "\n",
    "# Create model instance\n",
    "model = DrumTranscriptionModel(n_mels=229, n_drums=N_DRUMS, use_lstm=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Loss Functions\n",
    "\n",
    "We'll define a combined loss function that handles both onset detection (binary cross entropy) and velocity prediction (mean squared error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss_function(\n",
    "    onset_pred, \n",
    "    velocity_pred, \n",
    "    onset_target, \n",
    "    velocity_target, \n",
    "    onset_weight=0.8\n",
    "):\n",
    "    \"\"\"\n",
    "    Combined loss for both onset detection and velocity prediction.\n",
    "    \n",
    "    Args:\n",
    "        onset_pred: Onset predictions [B, n_drums, T]\n",
    "        velocity_pred: Velocity predictions [B, n_drums, T]\n",
    "        onset_target: Onset targets [B, n_drums, T]\n",
    "        velocity_target: Velocity targets [B, n_drums, T]\n",
    "        onset_weight: Weight for onset loss (velocity_weight = 1 - onset_weight)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (combined_loss, onset_loss, velocity_loss)\n",
    "    \"\"\"\n",
    "    # Binary cross entropy for onset detection\n",
    "    onset_loss = F.binary_cross_entropy(onset_pred, onset_target)\n",
    "    \n",
    "    # Only calculate velocity loss for positive onsets to match training target\n",
    "    # Create a mask where onsets exist\n",
    "    mask = onset_target > 0\n",
    "    \n",
    "    if mask.sum() > 0:  # If there are any positive onsets in this batch\n",
    "        velocity_loss = F.mse_loss(velocity_pred[mask], velocity_target[mask])\n",
    "    else:\n",
    "        velocity_loss = torch.tensor(0.0, device=onset_pred.device)\n",
    "    \n",
    "    # Combine losses with specified weighting\n",
    "    velocity_weight = 1.0 - onset_weight\n",
    "    combined = onset_weight * onset_loss + velocity_weight * velocity_loss\n",
    "    \n",
    "    return combined, onset_loss, velocity_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop\n",
    "\n",
    "Define functions to train the model and evaluate it on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, device, onset_weight=0.8):\n",
    "    \"\"\"Train the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_onset_loss = 0\n",
    "    epoch_velocity_loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    # Loop over batches\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        # Move data to device\n",
    "        inputs = batch[\"input\"].to(device)\n",
    "        onset_target = batch[\"onset_target\"].to(device)\n",
    "        velocity_target = batch[\"velocity_target\"].to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        onset_pred, velocity_pred = model(inputs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss, onset_loss, velocity_loss = combined_loss_function(\n",
    "            onset_pred, velocity_pred, onset_target, velocity_target, onset_weight\n",
    "        )\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_onset_loss += onset_loss.item()\n",
    "        epoch_velocity_loss += velocity_loss.item()\n",
    "        batch_count += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'o_loss': f\"{onset_loss.item():.4f}\",\n",
    "            'v_loss': f\"{velocity_loss.item():.4f}\"\n",
    "        })\n",
    "    \n",
    "    # Calculate average losses\n",
    "    return {\n",
    "        'loss': epoch_loss / batch_count,\n",
    "        'onset_loss': epoch_onset_loss / batch_count,\n",
    "        'velocity_loss': epoch_velocity_loss / batch_count\n",
    "    }\n",
    "\n",
    "def validate(model, val_loader, device, onset_weight=0.8):\n",
    "    \"\"\"Evaluate the model on validation data.\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_onset_loss = 0\n",
    "    val_velocity_loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    # For computing onset detection metrics\n",
    "    all_onset_preds = []\n",
    "    all_onset_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=\"Validating\")\n",
    "        for batch in progress_bar:\n",
    "            # Move data to device\n",
    "            inputs = batch[\"input\"].to(device)\n",
    "            onset_target = batch[\"onset_target\"].to(device)\n",
    "            velocity_target = batch[\"velocity_target\"].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            onset_pred, velocity_pred = model(inputs)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss, onset_loss, velocity_loss = combined_loss_function(\n",
    "                onset_pred, velocity_pred, onset_target, velocity_target, onset_weight\n",
    "            )\n",
    "            \n",
    "            # Update metrics\n",
    "            val_loss += loss.item()\n",
    "            val_onset_loss += onset_loss.item()\n",
    "            val_velocity_loss += velocity_loss.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "            # Store predictions for F1 calculation\n",
    "            all_onset_preds.append(onset_pred.detach().cpu().numpy())\n",
    "            all_onset_targets.append(onset_target.detach().cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'val_loss': f\"{loss.item():.4f}\",\n",
    "                'o_loss': f\"{onset_loss.item():.4f}\",\n",
    "                'v_loss': f\"{velocity_loss.item():.4f}\"\n",
    "            })\n",
    "    \n",
    "    # Calculate F1 score for onset detection\n",
    "    threshold = 0.5\n",
    "    all_preds = np.concatenate([p.reshape(-1) for p in all_onset_preds])\n",
    "    all_targets = np.concatenate([t.reshape(-1) for t in all_onset_targets])\n",
    "    \n",
    "    # Binarize predictions using threshold\n",
    "    binary_preds = (all_preds > threshold).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_targets, binary_preds, average='binary', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Calculate average losses\n",
    "    return {\n",
    "        'loss': val_loss / batch_count,\n",
    "        'onset_loss': val_onset_loss / batch_count,\n",
    "        'velocity_loss': val_velocity_loss / batch_count,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, \n",
    "                learning_rate=0.001, epochs=30, patience=5, onset_weight=0.8):\n",
    "    \"\"\"Train the model with early stopping and learning rate scheduling.\"\"\"\n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Track best validation performance for early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Track metrics for plotting\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    # Main training loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Train for one epoch\n",
    "        train_metrics = train_epoch(model, train_loader, optimizer, device, onset_weight)\n",
    "        train_loss = train_metrics['loss']\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validate\n",
    "        val_metrics = validate(model, val_loader, device, onset_weight)\n",
    "        val_loss = val_metrics['loss']\n",
    "        val_losses.append(val_loss)\n",
    "        f1_scores.append(val_metrics['f1'])\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{epochs} completed in {epoch_time:.2f}s\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} (Onset: {train_metrics['onset_loss']:.4f}, Velocity: {train_metrics['velocity_loss']:.4f})\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} (Onset: {val_metrics['onset_loss']:.4f}, Velocity: {val_metrics['velocity_loss']:.4f})\")\n",
    "        print(f\"F1 Score: {val_metrics['f1']:.4f}, Precision: {val_metrics['precision']:.4f}, Recall: {val_metrics['recall']:.4f}\")\n",
    "        \n",
    "        # Check for improvement\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Save the best model\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'f1_score': val_metrics['f1'],\n",
    "            }, MODEL_SAVE_DIR / 'drum_transcription_best.pt')\n",
    "            \n",
    "            print(f\"Saved best model with validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement for {patience_counter} epochs\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping after {epoch+1} epochs!\")\n",
    "                break\n",
    "    \n",
    "    # Save the final model\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'f1_score': val_metrics['f1'],\n",
    "    }, MODEL_SAVE_DIR / 'drum_transcription_final.pt')\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Loss History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(f1_scores, label='F1 Score', color='green')\n",
    "    plt.title('F1 Score History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, train_losses, val_losses, f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model\n",
    "\n",
    "Execute the training process. This will take some time depending on hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs = 30\n",
    "patience = 5\n",
    "onset_weight = 0.8  # Weight for onset loss (0.8 means 80% onset, 20% velocity)\n",
    "\n",
    "# Start training\n",
    "model, train_losses, val_losses, f1_scores = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    learning_rate=learning_rate,\n",
    "    epochs=epochs,\n",
    "    patience=patience,\n",
    "    onset_weight=onset_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate on Test Set\n",
    "\n",
    "Evaluate the best model on the test set to get an unbiased measure of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = MODEL_SAVE_DIR / 'drum_transcription_best.pt'\n",
    "checkpoint = torch.load(best_model_path, map_location=device)\n",
    "\n",
    "# Create a new model instance and load state\n",
    "best_model = DrumTranscriptionModel(n_mels=229, n_drums=N_DRUMS, use_lstm=True)\n",
    "best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1} with validation loss: {checkpoint['val_loss']:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics = validate(best_model, test_loader, device, onset_weight=onset_weight)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"Test Loss: {test_metrics['loss']:.4f} (Onset: {test_metrics['onset_loss']:.4f}, Velocity: {test_metrics['velocity_loss']:.4f})\")\n",
    "print(f\"F1 Score: {test_metrics['f1']:.4f}, Precision: {test_metrics['precision']:.4f}, Recall: {test_metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Predictions\n",
    "\n",
    "Let's visualize some predictions from the test set to qualitatively assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, data_loader, device, threshold=0.5, num_samples=3):\n",
    "    \"\"\"Visualize model predictions on a few samples.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    samples_seen = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs = batch[\"input\"].to(device)\n",
    "            onset_targets = batch[\"onset_target\"]\n",
    "            velocity_targets = batch[\"velocity_target\"]\n",
    "            file_paths = batch[\"file_paths\"]\n",
    "            \n",
    "            # Forward pass\n",
    "            onset_preds, velocity_preds = model(inputs)\n",
    "            onset_preds = onset_preds.cpu()\n",
    "            velocity_preds = velocity_preds.cpu()\n",
    "            \n",
    "            # Loop through each item in the batch\n",
    "            for i in range(min(inputs.size(0), num_samples - samples_seen)):\n",
    "                # Get a single sample\n",
    "                input_spec = inputs[i].cpu()\n",
    "                onset_target = onset_targets[i]\n",
    "                velocity_target = velocity_targets[i]\n",
    "                onset_pred = onset_preds[i]\n",
    "                velocity_pred = velocity_preds[i]\n",
    "                \n",
    "                # Create binary onset predictions\n",
    "                binary_onset = (onset_pred > threshold).float()\n",
    "                \n",
    "                # Create a mask for velocities based on predicted onsets\n",
    "                masked_velocity_pred = velocity_pred * binary_onset\n",
    "                \n",
    "                # Visualize\n",
    "                plt.figure(figsize=(15, 10))\n",
    "                \n",
    "                # Plot input spectrogram\n",
    "                plt.subplot(4, 1, 1)\n",
    "                plt.imshow(input_spec.numpy(), aspect='auto', origin='lower', cmap='viridis')\n",
    "                plt.colorbar()\n",
    "                plt.title('Mel Spectrogram')\n",
    "                plt.ylabel('Mel Bin')\n",
    "                \n",
    "                # Plot ground truth onsets\n",
    "                plt.subplot(4, 1, 2)\n",
    "                plt.imshow(onset_target.numpy(), aspect='auto', origin='lower', cmap='Reds')\n",
    "                plt.colorbar()\n",
    "                plt.title('Ground Truth Onsets')\n",
    "                plt.yticks(np.arange(N_DRUMS), MAIN_DRUM_NAMES)\n",
    "                \n",
    "                # Plot predicted onsets (binary)\n",
    "                plt.subplot(4, 1, 3)\n",
    "                plt.imshow(binary_onset.numpy(), aspect='auto', origin='lower', cmap='OrRd')\n",
    "                plt.colorbar()\n",
    "                plt.title(f'Predicted Onsets (threshold={threshold})')\n",
    "                plt.yticks(np.arange(N_DRUMS), MAIN_DRUM_NAMES)\n",
    "                \n",
    "                # Plot predicted velocities (masked by onset predictions)\n",
    "                plt.subplot(4, 1, 4)\n",
    "                plt.imshow(masked_velocity_pred.numpy(), aspect='auto', origin='lower', cmap='Blues')\n",
    "                plt.colorbar()\n",
    "                plt.title('Predicted Velocities (only where onset predicted)')\n",
    "                plt.yticks(np.arange(N_DRUMS), MAIN_DRUM_NAMES)\n",
    "                plt.xlabel('Time Frame')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Show the file path of this example\n",
    "                print(f\"File: {file_paths[i]}\")\n",
    "                \n",
    "                samples_seen += 1\n",
    "            \n",
    "            if samples_seen >= num_samples:\n",
    "                break\n",
    "\n",
    "# Visualize some predictions\n",
    "visualize_predictions(best_model, test_loader, device, threshold=0.5, num_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've successfully built and trained a deep learning model for drum transcription. The model has dual outputs: one for detecting drum onsets (when a drum is hit) and another for predicting the velocity (how hard it's hit).\n",
    "\n",
    "**Key accomplishments:**\n",
    "\n",
    "1. Created a PyTorch dataset for loading processed training examples\n",
    "2. Designed a CNN/CRNN architecture with dual output heads\n",
    "3. Implemented a combined loss function for multi-task learning\n",
    "4. Trained the model with early stopping and learning rate scheduling\n",
    "5. Evaluated performance using appropriate metrics\n",
    "6. Visualized predictions alongside ground truth\n",
    "\n",
    "The F1 score on the test set gives us an idea of how well the model is detecting drum hits. In our next notebook, we'll explore how to convert these predictions into MIDI files and evaluate the full transcription system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
