{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Model Development & Training\n",
    "\n",
    "**Objective:** Design and train a deep learning model that predicts both drum onsets and velocities from mel spectrograms.\n",
    "\n",
    "This notebook implements our drum transcription neural network architecture, loss functions, and training pipeline. The model has dual heads for both onset detection and velocity prediction, allowing it to capture not just when a drum is hit but also how hard it's played."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup\n",
    "\n",
    "Loading required libraries for model development, training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This so the GPU doesnt crash\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "# For reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(\"../data\")\n",
    "PROCESSED_DATA_DIR = DATA_DIR / \"processed\"\n",
    "MODEL_SAVE_DIR = Path(\"../models\")\n",
    "MODEL_SAVE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Drum mapping (same as in previous notebooks)\n",
    "GM_DRUM_MAPPING = {\n",
    "        36: \"Kick\",\n",
    "        38: \"Snare\",\n",
    "        42: \"HiHat\",\n",
    "        47: \"Tom\",\n",
    "        49: \"Crash\",\n",
    "        51: \"Ride\"\n",
    "    }\n",
    "\n",
    "# Drum types constants\n",
    "MAIN_DRUMS = list(GM_DRUM_MAPPING.keys())\n",
    "MAIN_DRUM_NAMES = list(GM_DRUM_MAPPING.values())\n",
    "N_DRUMS = len(MAIN_DRUMS)\n",
    "\n",
    "# Configure plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "def save_checkpoint(model, optimizer, scheduler, epoch, train_losses, val_losses, f1_scores,\n",
    "                   best_val_loss, patience_counter, filename):\n",
    "    \"\"\"Save a complete checkpoint that can be used to resume training.\"\"\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'f1_scores': f1_scores,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'patience_counter': patience_counter\n",
    "    }, filename)\n",
    "    print(f\"Checkpoint saved to {filename}\")\n",
    "\n",
    "def load_checkpoint(filename, model, optimizer, scheduler=None):\n",
    "    \"\"\"Load a checkpoint to resume training.\"\"\"\n",
    "    if not Path(filename).exists():\n",
    "        print(f\"Checkpoint {filename} not found. Starting from scratch.\")\n",
    "        return 0, [], [], [], float('inf'), 0\n",
    "\n",
    "    print(f\"Loading checkpoint from {filename}\")\n",
    "    checkpoint = torch.load(filename, map_location=device)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    if scheduler and 'scheduler_state_dict' in checkpoint:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "    start_epoch = checkpoint['epoch'] + 1  # Resume from next epoch\n",
    "    train_losses = checkpoint['train_losses']\n",
    "    val_losses = checkpoint['val_losses']\n",
    "    f1_scores = checkpoint['f1_scores']\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "    patience_counter = checkpoint['patience_counter']\n",
    "\n",
    "    return start_epoch, train_losses, val_losses, f1_scores, best_val_loss, patience_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Dataset and DataLoader\n",
    "\n",
    "Loading our preprocessed training examples (.npz files) and setting up the PyTorch data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this function to sample a smaller dataset\n",
    "def create_small_dataset(data_dir, split, max_files=20):\n",
    "    \"\"\"Create a small toy dataset for testing the pipeline.\"\"\"\n",
    "    full_dir = Path(data_dir) / split\n",
    "    all_files = list(full_dir.glob(\"*.npz\"))\n",
    "\n",
    "    print(f\"Found {len(all_files)} total files for {split}\")\n",
    "    if len(all_files) <= max_files:\n",
    "        return all_files\n",
    "\n",
    "    # Take a random sample of files\n",
    "    sampled_files = random.sample(all_files, max_files)\n",
    "    print(f\"Sampled {len(sampled_files)} files for {split} toy dataset\")\n",
    "    return sampled_files\n",
    "\n",
    "# Modify the dataset class initialization\n",
    "class DrumTranscriptionDataset(Dataset):\n",
    "    \"\"\"Dataset for loading preprocessed drum transcription examples.\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir, split=\"train\", toy_mode=False, max_files=20):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "\n",
    "        Args:\n",
    "            data_dir: Directory containing the processed data\n",
    "            split: Which dataset split to use ('train', 'validation', or 'test')\n",
    "            toy_mode: If True, use only a small subset of files\n",
    "            max_files: Maximum number of files to use in toy mode\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir) / split\n",
    "\n",
    "        #\n",
    "        self.use_checkpoint = True\n",
    "\n",
    "        if toy_mode:\n",
    "            self.file_list = create_small_dataset(data_dir, split, max_files)\n",
    "        else:\n",
    "            self.file_list = list(self.data_dir.glob(\"*.npz\"))\n",
    "\n",
    "        if len(self.file_list) == 0:\n",
    "            raise ValueError(f\"No .npz files found in {self.data_dir}\")\n",
    "\n",
    "        print(f\"Using {len(self.file_list)} examples in {split} set\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the NPZ file\n",
    "        data = np.load(self.file_list[idx])\n",
    "\n",
    "        # Extract features and targets\n",
    "        mel_spec = data[\"mel_spec\"].astype(np.float32)  # [n_mels, n_frames]\n",
    "        onset_target = data[\"onset_target\"].astype(np.float32)  # [n_drums, n_frames]\n",
    "        velocity_target = data[\"velocity_target\"].astype(np.float32)  # [n_drums, n_frames]\n",
    "\n",
    "        # Add normalization to ensure inputs are scaled properly\n",
    "        mel_spec = (mel_spec - mel_spec.mean()) / (mel_spec.std() + 1e-8)\n",
    "\n",
    "        # Convert to tensors\n",
    "        mel_spec = torch.from_numpy(mel_spec)\n",
    "        onset_target = torch.from_numpy(onset_target)\n",
    "        velocity_target = torch.from_numpy(velocity_target)\n",
    "\n",
    "        return {\n",
    "            \"input\": mel_spec,\n",
    "            \"onset_target\": onset_target,\n",
    "            \"velocity_target\": velocity_target,\n",
    "            \"file_path\": str(self.file_list[idx])\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle variable-length sequences.\n",
    "    Pads sequences to the maximum length in the batch.\n",
    "    \"\"\"\n",
    "    # Get max sequence length in this batch\n",
    "    max_frames = max(item[\"input\"].shape[1] for item in batch)\n",
    "\n",
    "    # Initialize tensors for batched data\n",
    "    batch_size = len(batch)\n",
    "    n_mels = batch[0][\"input\"].shape[0]\n",
    "    n_drums = batch[0][\"onset_target\"].shape[0]\n",
    "\n",
    "    # Create padded tensors\n",
    "    inputs = torch.zeros((batch_size, n_mels, max_frames))\n",
    "    onset_targets = torch.zeros((batch_size, n_drums, max_frames))\n",
    "    velocity_targets = torch.zeros((batch_size, n_drums, max_frames))\n",
    "    file_paths = []\n",
    "\n",
    "    # Fill in the data\n",
    "    for i, item in enumerate(batch):\n",
    "        frames = item[\"input\"].shape[1]\n",
    "        inputs[i, :, :frames] = item[\"input\"]\n",
    "        onset_targets[i, :, :frames] = item[\"onset_target\"]\n",
    "        velocity_targets[i, :, :frames] = item[\"velocity_target\"]\n",
    "        file_paths.append(item[\"file_path\"])\n",
    "\n",
    "    return {\n",
    "        \"input\": inputs,\n",
    "        \"onset_target\": onset_targets,\n",
    "        \"velocity_target\": velocity_targets,\n",
    "        \"file_paths\": file_paths\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = DrumTranscriptionDataset(PROCESSED_DATA_DIR, split=\"train\")\n",
    "val_dataset = DrumTranscriptionDataset(PROCESSED_DATA_DIR, split=\"validation\")\n",
    "test_dataset = DrumTranscriptionDataset(PROCESSED_DATA_DIR, split=\"test\")\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 1\n",
    "num_workers = 1\n",
    "pin_memory = False\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Inspect a Batch\n",
    "\n",
    "Let's examine a batch of data to understand the input and target formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from the training loader\n",
    "for batch in train_loader:\n",
    "    inputs = batch[\"input\"]\n",
    "    onset_targets = batch[\"onset_target\"]\n",
    "    velocity_targets = batch[\"velocity_target\"]\n",
    "\n",
    "    print(f\"Input shape: {inputs.shape}\")  # [batch_size, n_mels, n_frames]\n",
    "    print(f\"Onset target shape: {onset_targets.shape}\")  # [batch_size, n_drums, n_frames]\n",
    "    print(f\"Velocity target shape: {velocity_targets.shape}\")  # [batch_size, n_drums, n_frames]\n",
    "\n",
    "    # Plot one example\n",
    "    idx = 0  # First example in batch\n",
    "    plt.figure(figsize=(15, 9))\n",
    "\n",
    "    # Plot mel spectrogram\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.imshow(inputs[idx].numpy(), aspect='auto', origin='lower', cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.title('Mel Spectrogram')\n",
    "    plt.ylabel('Mel Frequency Bin')\n",
    "\n",
    "    # Plot onset targets\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.imshow(onset_targets[idx].numpy(), aspect='auto', origin='lower', cmap='Reds')\n",
    "    plt.colorbar()\n",
    "    plt.title('Drum Onsets')\n",
    "    plt.yticks(np.arange(N_DRUMS), MAIN_DRUM_NAMES)\n",
    "\n",
    "    # Plot velocity targets\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.imshow(velocity_targets[idx].numpy(), aspect='auto', origin='lower', cmap='Blues')\n",
    "    plt.colorbar()\n",
    "    plt.title('Drum Velocities (Normalized 0-1)')\n",
    "    plt.yticks(np.arange(N_DRUMS), MAIN_DRUM_NAMES)\n",
    "    plt.xlabel('Time Frames')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Just examine one batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Model Architecture\n",
    "\n",
    "Create our drum transcription model based on a CNN architecture with dual output heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Convolutional block with batch normalization and ReLU activation.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class DrumTranscriptionModel(nn.Module):\n",
    "    \"\"\"CNN model for drum transcription with dual output heads.\"\"\"\n",
    "\n",
    "    def __init__(self, n_mels=229, n_drums=6, use_lstm=True, dropout=0.3):\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "\n",
    "        Args:\n",
    "            n_mels: Number of mel frequency bands in input\n",
    "            n_drums: Number of drum types to detect\n",
    "            use_lstm: Whether to use LSTM layers for temporal modeling\n",
    "        \"\"\"\n",
    "        super(DrumTranscriptionModel, self).__init__()\n",
    "        self.n_mels = n_mels\n",
    "        self.n_drums = n_drums\n",
    "        self.use_lstm = use_lstm\n",
    "\n",
    "        # Feature extraction: convolutional layers\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            # Layer 1: [B, 1, n_mels, T] -> [B, 32, n_mels//2, T]\n",
    "            ConvBlock(1, 32),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),  # Frequency pooling\n",
    "\n",
    "            # Layer 2: [B, 32, n_mels//2, T] -> [B, 64, n_mels//4, T]\n",
    "            ConvBlock(32, 64),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),  # Frequency pooling\n",
    "\n",
    "            # Layer 3: [B, 64, n_mels//4, T] -> [B, 128, n_mels//8, T]\n",
    "            ConvBlock(64, 128),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),  # Frequency pooling\n",
    "\n",
    "            # Layer 4: [B, 128, n_mels//8, T] -> [B, 128, n_mels//16, T]\n",
    "            ConvBlock(128, 128),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))   # Frequency pooling\n",
    "        )\n",
    "\n",
    "        # Calculate feature dimensions after CNN\n",
    "        self.cnn_output_freq_dim = n_mels // 16\n",
    "        self.cnn_output_channels = 128\n",
    "        self.cnn_output_dim = self.cnn_output_channels * self.cnn_output_freq_dim\n",
    "\n",
    "        # Optional: Bi-directional LSTM layer for temporal modeling\n",
    "        if self.use_lstm:\n",
    "            self.lstm = nn.LSTM(\n",
    "                input_size=self.cnn_output_dim,\n",
    "                hidden_size=256, num_layers=1, batch_first=True,\n",
    "                bidirectional=True, dropout=dropout if dropout > 0 else 0 # LSTM dropout only applied if num_layers > 1\n",
    "            )\n",
    "            # Apply dropout after LSTM if specified and num_layers is 1\n",
    "            self.lstm_dropout = nn.Dropout(dropout) if dropout > 0 and self.lstm.num_layers == 1 else nn.Identity()\n",
    "            feature_dim = 512 # bidirectional LSTM output (2 * hidden_size)\n",
    "        else:\n",
    "            feature_dim = self.cnn_output_dim\n",
    "            self.lstm = None\n",
    "            self.lstm_dropout = nn.Identity()\n",
    "\n",
    "        # Onset detection head\n",
    "        self.onset_head = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, n_drums),\n",
    "            # nn.Sigmoid()  # BCE with logits loss\n",
    "        )\n",
    "\n",
    "        # Velocity prediction head\n",
    "        self.velocity_head = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, n_drums),\n",
    "            # ReLU so that we dont have negatives\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape [batch_size, n_mels, n_frames]\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (onset_predictions, velocity_predictions)\n",
    "        \"\"\"\n",
    "        batch_size, n_mels, n_frames = x.shape\n",
    "        x = x.unsqueeze(1) # [B, 1, n_mels, T]\n",
    "\n",
    "        # CNN forward\n",
    "        x = self.conv_stack(x) # [B, C, n_mels_reduced, T]\n",
    "\n",
    "        # Reshape for RNN/Linear\n",
    "        x = x.permute(0, 3, 1, 2) # [B, T, C, n_mels_reduced]\n",
    "        # Combine channel and frequency dims\n",
    "        x = x.reshape(batch_size, n_frames, self.cnn_output_dim) # [B, T, C * n_mels_reduced]\n",
    "\n",
    "        # Optional LSTM forward\n",
    "        if self.use_lstm:\n",
    "            x, _ = self.lstm(x) # [B, T, 2 * hidden_size]\n",
    "            x = self.lstm_dropout(x) # Apply dropout\n",
    "\n",
    "        # Output heads forward\n",
    "        onset_logits = self.onset_head(x) # [B, T, n_drums] - Logits\n",
    "        velocity_pred = self.velocity_head(x) # [B, T, n_drums] - Velocities >= 0\n",
    "\n",
    "        # Reshape to match target format [B, n_drums, T]\n",
    "        onset_logits = onset_logits.transpose(1, 2)\n",
    "        velocity_pred = velocity_pred.transpose(1, 2)\n",
    "\n",
    "        # onset_logits are the raw outputs before sigmoid\n",
    "        # velocity_pred are the predicted velocities (>= 0 due to final ReLU)\n",
    "        return onset_logits, velocity_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Loss Functions\n",
    "\n",
    "We'll define a combined loss function that handles both onset detection (binary cross entropy) and velocity prediction (mean squared error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss_function(\n",
    "    onset_pred,\n",
    "    velocity_pred,\n",
    "    onset_target,\n",
    "    velocity_target,\n",
    "    onset_weight=0.8,\n",
    "    positive_weight=10.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Combined loss for both onset detection and velocity prediction.\n",
    "\n",
    "    Args:\n",
    "        onset_pred: Onset predictions [B, n_drums, T]\n",
    "        velocity_pred: Velocity predictions [B, n_drums, T]\n",
    "        onset_target: Onset targets [B, n_drums, T]\n",
    "        velocity_target: Velocity targets [B, n_drums, T]\n",
    "        onset_weight: Weight for onset loss (velocity_weight = 1 - onset_weight)\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (combined_loss, onset_loss, velocity_loss)\n",
    "    \"\"\"\n",
    "    # Create weight tensor with high values for positive examples\n",
    "    weights = torch.ones_like(onset_target)\n",
    "    weights[onset_target > 0] = positive_weight\n",
    "\n",
    "    # Use binary_cross_entropy_with_logits instead of binary_cross_entropy\n",
    "    onset_loss = F.binary_cross_entropy_with_logits(onset_pred, onset_target, weight=weights)\n",
    "\n",
    "    # For velocity prediction with masked loss, need probabilities from logits\n",
    "    onset_probs = torch.sigmoid(onset_pred)\n",
    "\n",
    "    # Rest of the function stays the same\n",
    "    mask = onset_target > 0\n",
    "    if mask.sum() > 0:\n",
    "        velocity_loss = F.mse_loss(velocity_pred[mask], velocity_target[mask])\n",
    "    else:\n",
    "        velocity_loss = torch.tensor(0.0, device=onset_pred.device)\n",
    "\n",
    "    velocity_weight = 1.0 - onset_weight\n",
    "    combined = onset_weight * onset_loss + velocity_weight * velocity_loss\n",
    "\n",
    "    return combined, onset_loss, velocity_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop\n",
    "\n",
    "Define functions to train the model and evaluate it on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights for better performance\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, device, onset_weight=0.8, scaler=None, accum_steps=4):\n",
    "    \"\"\"Train the model for one epoch with gradient accumulation and mixed precision.\"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_onset_loss = 0\n",
    "    epoch_velocity_loss = 0\n",
    "    batch_count = 0\n",
    "    optimizer.zero_grad()  # Zero gradients once at the beginning\n",
    "\n",
    "    # Loop over batches\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    for i, batch in enumerate(progress_bar):\n",
    "        # Move data to device\n",
    "        inputs = batch[\"input\"].to(device)\n",
    "        onset_target = batch[\"onset_target\"].to(device)\n",
    "        velocity_target = batch[\"velocity_target\"].to(device)\n",
    "\n",
    "        # Forward pass with mixed precision\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            onset_pred, velocity_pred = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss, onset_loss, velocity_loss = combined_loss_function(\n",
    "                onset_pred, velocity_pred, onset_target, velocity_target, onset_weight\n",
    "            )\n",
    "\n",
    "            # Scale the loss by accumulation steps\n",
    "            loss = loss / accum_steps\n",
    "\n",
    "        # Backward pass with scaled gradients\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Only update weights after accumulating gradients for accum_steps batches\n",
    "        if (i + 1) % accum_steps == 0 or (i + 1) == len(train_loader):\n",
    "            # Unscale before optimizer step (helps with gradient clipping if used)\n",
    "            scaler.unscale_(optimizer)\n",
    "\n",
    "            # Update weights with scaling aware step\n",
    "            scaler.step(optimizer)\n",
    "\n",
    "            # Update the scaler\n",
    "            scaler.update()\n",
    "\n",
    "            # Zero gradients for next batch\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # For metrics tracking, use the unscaled loss\n",
    "        actual_loss = loss.item() * accum_steps\n",
    "        epoch_loss += actual_loss\n",
    "        epoch_onset_loss += onset_loss.item()\n",
    "        epoch_velocity_loss += velocity_loss.item()\n",
    "        batch_count += 1\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f\"{actual_loss:.4f}\",\n",
    "            'o_loss': f\"{onset_loss.item():.4f}\",\n",
    "            'v_loss': f\"{velocity_loss.item():.4f}\"\n",
    "        })\n",
    "\n",
    "    # Calculate average losses\n",
    "    return {\n",
    "        'loss': epoch_loss / batch_count,\n",
    "        'onset_loss': epoch_onset_loss / batch_count,\n",
    "        'velocity_loss': epoch_velocity_loss / batch_count\n",
    "    }\n",
    "\n",
    "# Replace both current validation functions with this single one\n",
    "def validate(model, val_loader, device, onset_weight=0.8, positive_weight=10.0, fixed_threshold=None):\n",
    "    \"\"\"\n",
    "    Evaluate the model on validation data with threshold optimization.\n",
    "\n",
    "    Args:\n",
    "        model: The model to evaluate\n",
    "        val_loader: DataLoader for validation data\n",
    "        device: Device to run on (CPU or GPU)\n",
    "        onset_weight: Weight for onset loss\n",
    "        positive_weight: Weight for positive examples in BCE loss\n",
    "        fixed_threshold: If provided, use this threshold instead of optimizing\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of metrics including optimized threshold\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_onset_loss = 0\n",
    "    val_velocity_loss = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    # For computing onset detection metrics\n",
    "    all_onset_preds = []\n",
    "    all_onset_targets = []\n",
    "    all_drum_preds = {i: [] for i in range(len(MAIN_DRUM_NAMES))}\n",
    "    all_drum_targets = {i: [] for i in range(len(MAIN_DRUM_NAMES))}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=\"Validating\")\n",
    "        for batch in progress_bar:\n",
    "            # Move data to device\n",
    "            inputs = batch[\"input\"].to(device)\n",
    "            onset_target = batch[\"onset_target\"].to(device)\n",
    "            velocity_target = batch[\"velocity_target\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            onset_pred, velocity_pred = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss, onset_loss, velocity_loss = combined_loss_function(\n",
    "                onset_pred, velocity_pred, onset_target, velocity_target,\n",
    "                onset_weight=onset_weight,\n",
    "                positive_weight=positive_weight\n",
    "            )\n",
    "\n",
    "            # Convert to probabilities for metrics\n",
    "            onset_probs = torch.sigmoid(onset_pred)\n",
    "\n",
    "            # Update metrics\n",
    "            val_loss += loss.item()\n",
    "            val_onset_loss += onset_loss.item()\n",
    "            val_velocity_loss += velocity_loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "            # Store predictions for F1 calculation\n",
    "            onset_probs_np = onset_probs.detach().cpu().numpy()\n",
    "            onset_target_np = onset_target.detach().cpu().numpy()\n",
    "            all_onset_preds.append(onset_probs_np.reshape(-1))\n",
    "            all_onset_targets.append(onset_target_np.reshape(-1))\n",
    "\n",
    "            # Store per-drum predictions\n",
    "            for i in range(len(MAIN_DRUM_NAMES)):\n",
    "                all_drum_preds[i].extend(onset_probs_np[:, i, :].flatten())\n",
    "                all_drum_targets[i].extend(onset_target_np[:, i, :].flatten())\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'val_loss': f\"{loss.item():.4f}\",\n",
    "                'o_loss': f\"{onset_loss.item():.4f}\",\n",
    "                'v_loss': f\"{velocity_loss.item():.4f}\"\n",
    "            })\n",
    "\n",
    "    # Flatten all predictions and targets\n",
    "    all_preds = np.concatenate(all_onset_preds)\n",
    "    all_targets = np.concatenate(all_onset_targets)\n",
    "\n",
    "    # If a fixed threshold is provided, use it. Otherwise, optimize.\n",
    "    if fixed_threshold is not None:\n",
    "        best_threshold = fixed_threshold\n",
    "        binary_preds = (all_preds > best_threshold).astype(int)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_targets, binary_preds, average='binary', zero_division=0\n",
    "        )\n",
    "        best_precision = precision\n",
    "        best_recall = recall\n",
    "        best_f1 = f1\n",
    "        print(f\"Using fixed threshold: {best_threshold:.2f}, F1: {best_f1:.4f}\")\n",
    "    else:\n",
    "        # Try different thresholds to find best F1\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5\n",
    "        best_precision = 0\n",
    "        best_recall = 0\n",
    "\n",
    "        # Test thresholds in a range\n",
    "        for threshold in np.arange(0.2, 0.8, 0.05):\n",
    "            binary_preds = (all_preds > threshold).astype(int)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                all_targets, binary_preds, average='binary', zero_division=0\n",
    "            )\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "                best_precision = precision\n",
    "                best_recall = recall\n",
    "\n",
    "        print(f\"Best threshold: {best_threshold:.2f} with F1: {best_f1:.4f}\")\n",
    "\n",
    "    # Per-drum metrics with best threshold\n",
    "    drum_metrics = {}\n",
    "    for i, drum_name in enumerate(MAIN_DRUM_NAMES):\n",
    "        drum_preds = np.array(all_drum_preds[i])\n",
    "        drum_targets = np.array(all_drum_targets[i])\n",
    "\n",
    "        binary_preds = (drum_preds > best_threshold).astype(int)\n",
    "        p, r, f1, _ = precision_recall_fscore_support(\n",
    "            drum_targets, binary_preds, average='binary', zero_division=0\n",
    "        )\n",
    "        drum_metrics[drum_name] = {'precision': p, 'recall': r, 'f1': f1}\n",
    "\n",
    "    # Calculate average losses\n",
    "    return {\n",
    "        'loss': val_loss / batch_count,\n",
    "        'onset_loss': val_onset_loss / batch_count,\n",
    "        'velocity_loss': val_velocity_loss / batch_count,\n",
    "        'precision': best_precision,\n",
    "        'recall': best_recall,\n",
    "        'f1': best_f1,\n",
    "        'threshold': best_threshold,\n",
    "        'drum_metrics': drum_metrics\n",
    "    }\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device,\n",
    "                learning_rate=0.001, epochs=30, patience=5, onset_weight=0.8,\n",
    "                resume_from=None, accum_steps=8):\n",
    "    \"\"\"Train the model with early stopping, learning rate scheduling, and checkpointing.\"\"\"\n",
    "\n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3\n",
    "    )\n",
    "\n",
    "    # Enable mixed precision training\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "    # Track metrics\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    f1_scores = []\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    checkpoint_dir = MODEL_SAVE_DIR / 'checkpoints'\n",
    "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Resume training if a checkpoint is provided\n",
    "    if resume_from:\n",
    "        start_epoch, train_losses, val_losses, f1_scores, best_val_loss, patience_counter = load_checkpoint(\n",
    "            resume_from, model, optimizer, scheduler\n",
    "        )\n",
    "        print(f\"Resuming training from epoch {start_epoch}\")\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Check memory useage\n",
    "        print(f\"VRAM used: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "        print(f\"VRAM free: {(12 - torch.cuda.max_memory_allocated() / 1e9):.2f} GB\")\n",
    "\n",
    "        # Train for one epoch\n",
    "        train_metrics = train_epoch(model, train_loader, optimizer, device, onset_weight, scaler, accum_steps=accum_steps)\n",
    "        train_loss = train_metrics['loss']\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validate\n",
    "        val_metrics = validate(model, val_loader, device, onset_weight)\n",
    "        val_loss = val_metrics['loss']\n",
    "        val_losses.append(val_loss)\n",
    "        f1_scores.append(val_metrics['f1'])\n",
    "\n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Print epoch summary\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{epochs} completed in {epoch_time:.2f}s\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} (Onset: {train_metrics['onset_loss']:.4f}, Velocity: {train_metrics['velocity_loss']:.4f})\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} (Onset: {val_metrics['onset_loss']:.4f}, Velocity: {val_metrics['velocity_loss']:.4f})\")\n",
    "        print(f\"F1 Score: {val_metrics['f1']:.4f}, Precision: {val_metrics['precision']:.4f}, Recall: {val_metrics['recall']:.4f}\")\n",
    "\n",
    "        # Save regular checkpoint after each epoch\n",
    "        checkpoint_path = checkpoint_dir / f\"checkpoint_epoch_{epoch+1}.pt\"\n",
    "        save_checkpoint(\n",
    "            model, optimizer, scheduler, epoch, train_losses, val_losses,\n",
    "            f1_scores, best_val_loss, patience_counter, checkpoint_path\n",
    "        )\n",
    "\n",
    "        # Also save latest checkpoint (overwriting the previous one)\n",
    "        latest_path = checkpoint_dir / \"checkpoint_latest.pt\"\n",
    "        save_checkpoint(\n",
    "            model, optimizer, scheduler, epoch, train_losses, val_losses,\n",
    "            f1_scores, best_val_loss, patience_counter, latest_path\n",
    "        )\n",
    "\n",
    "        # Automatically download checkpoints every few epochs if in Colab\n",
    "        if 'google.colab' in sys.modules and (epoch % 5 == 0 or epoch == epochs-1):\n",
    "            try:\n",
    "                from google.colab import files\n",
    "                print(\"\\nDownloading checkpoint files to prevent data loss...\")\n",
    "\n",
    "                # Download best model if it exists\n",
    "                best_model_path = MODEL_SAVE_DIR / 'drum_transcription_best.pt'\n",
    "                if best_model_path.exists():\n",
    "                    files.download(str(best_model_path))\n",
    "                    print(\"Downloaded best model\")\n",
    "\n",
    "                # Download latest checkpoint\n",
    "                files.download(str(latest_path))\n",
    "                print(\"Downloaded latest checkpoint\")\n",
    "\n",
    "                # Continue training without interruption\n",
    "            except Exception as e:\n",
    "                print(f\"Could not download automatically: {e}\")\n",
    "                print(\"Consider manually running the download_checkpoints() function in a separate cell\")\n",
    "\n",
    "        # Check for improvement and save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "\n",
    "            # Save the best model\n",
    "            best_model_path = MODEL_SAVE_DIR / 'drum_transcription_best.pt'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'f1_score': val_metrics['f1'],\n",
    "            }, best_model_path)\n",
    "\n",
    "            print(f\"Saved best model with validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement for {patience_counter} epochs\")\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping after {epoch+1} epochs!\")\n",
    "                break\n",
    "\n",
    "    # Save the final model\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'f1_score': val_metrics['f1'],\n",
    "    }, MODEL_SAVE_DIR / 'drum_transcription_final.pt')\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Loss History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(f1_scores, label='F1 Score', color='green')\n",
    "    plt.title('F1 Score History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return model, train_losses, val_losses, f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, data_loader, device, threshold=0.5, num_samples=3):\n",
    "    \"\"\"Visualize model predictions on a few samples.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    samples_seen = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs = batch[\"input\"].to(device)\n",
    "            onset_targets = batch[\"onset_target\"]\n",
    "            velocity_targets = batch[\"velocity_target\"]\n",
    "            file_paths = batch[\"file_paths\"]\n",
    "\n",
    "            # Forward pass\n",
    "            onset_preds, velocity_preds = model(inputs)\n",
    "            onset_preds = onset_preds.cpu()\n",
    "            onset_probs = torch.sigmoid(onset_preds)\n",
    "            velocity_preds = velocity_preds.cpu()\n",
    "\n",
    "            # Loop through each item in the batch\n",
    "            for i in range(min(inputs.size(0), num_samples - samples_seen)):\n",
    "                # Get a single sample\n",
    "                input_spec = inputs[i].cpu()\n",
    "                onset_target = onset_targets[i]\n",
    "                velocity_target = velocity_targets[i]\n",
    "                onset_pred = onset_preds[i]\n",
    "                velocity_pred = velocity_preds[i]\n",
    "\n",
    "                # Create binary onset predictions - fix applied here\n",
    "                binary_onset = (onset_probs[i] > threshold).float()\n",
    "\n",
    "                # Create a mask for velocities based on predicted onsets\n",
    "                masked_velocity_pred = velocity_pred * binary_onset\n",
    "\n",
    "                # Visualize\n",
    "                plt.figure(figsize=(15, 10))\n",
    "\n",
    "                # Plot input spectrogram\n",
    "                plt.subplot(4, 1, 1)\n",
    "                plt.imshow(input_spec.numpy(), aspect='auto', origin='lower', cmap='viridis')\n",
    "                plt.colorbar()\n",
    "                plt.title('Mel Spectrogram')\n",
    "                plt.ylabel('Mel Bin')\n",
    "\n",
    "                # Plot ground truth onsets\n",
    "                plt.subplot(4, 1, 2)\n",
    "                plt.imshow(onset_target.numpy(), aspect='auto', origin='lower', cmap='Reds')\n",
    "                plt.colorbar()\n",
    "                plt.title('Ground Truth Onsets')\n",
    "                plt.yticks(np.arange(N_DRUMS), MAIN_DRUM_NAMES)\n",
    "\n",
    "                # Plot predicted onsets (binary)\n",
    "                plt.subplot(4, 1, 3)\n",
    "                plt.imshow(binary_onset.numpy(), aspect='auto', origin='lower', cmap='OrRd')\n",
    "                plt.colorbar()\n",
    "                plt.title(f'Predicted Onsets (threshold={threshold})')\n",
    "                plt.yticks(np.arange(N_DRUMS), MAIN_DRUM_NAMES)\n",
    "\n",
    "                # Plot predicted velocities (masked by onset predictions)\n",
    "                plt.subplot(4, 1, 4)\n",
    "                plt.imshow(masked_velocity_pred.numpy(), aspect='auto', origin='lower', cmap='Blues')\n",
    "                plt.colorbar()\n",
    "                plt.title('Predicted Velocities (only where onset predicted)')\n",
    "                plt.yticks(np.arange(N_DRUMS), MAIN_DRUM_NAMES)\n",
    "                plt.xlabel('Time Frame')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                # Show the file path of this example\n",
    "                print(f\"File: {file_paths[i]}\")\n",
    "\n",
    "                samples_seen += 1\n",
    "\n",
    "            if samples_seen >= num_samples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_hyperparameters(train_loader, val_loader, device, max_epochs=10):\n",
    "    \"\"\"\n",
    "    Run a grid search over key hyperparameters and return the best configuration.\n",
    "    \"\"\"\n",
    "    # Define grid search parameters\n",
    "    param_grid = {\n",
    "        'use_lstm': [True, False],\n",
    "        'positive_weight': [10.0, 15.0, 20.0],\n",
    "        'dropout': [0.2, 0.3, 0.5],\n",
    "        'learning_rate': [0.001, 0.002, 0.005],\n",
    "        'onset_weight': [0.7, 0.8, 0.9]\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    best_f1 = 0\n",
    "    best_config = {}\n",
    "\n",
    "    print(\"Starting grid search...\")\n",
    "\n",
    "    # Generate configs to try (limited number for practicality)\n",
    "    configs = []\n",
    "    for use_lstm in param_grid['use_lstm']:\n",
    "        for pos_weight in param_grid['positive_weight']:\n",
    "            for dropout in param_grid['dropout']:\n",
    "                # Limit combinations to make search practical\n",
    "                if use_lstm:\n",
    "                    configs.append({\n",
    "                        'use_lstm': use_lstm,\n",
    "                        'positive_weight': pos_weight,\n",
    "                        'dropout': dropout,\n",
    "                        'learning_rate': 0.002,  # Fixed for LSTM\n",
    "                        'onset_weight': 0.8      # Fixed for LSTM\n",
    "                    })\n",
    "                else:\n",
    "                    configs.append({\n",
    "                        'use_lstm': use_lstm,\n",
    "                        'positive_weight': pos_weight,\n",
    "                        'dropout': dropout,\n",
    "                        'learning_rate': 0.005,  # Fixed for CNN\n",
    "                        'onset_weight': 0.8      # Fixed for CNN\n",
    "                    })\n",
    "\n",
    "    print(f\"Will evaluate {len(configs)} configurations\")\n",
    "\n",
    "    for i, config in enumerate(configs):\n",
    "        print(f\"\\nTesting configuration {i+1}/{len(configs)}:\")\n",
    "        print(config)\n",
    "\n",
    "        # Create and initialize model\n",
    "        model = DrumTranscriptionModel(\n",
    "            n_mels=229,\n",
    "            n_drums=N_DRUMS,\n",
    "            use_lstm=config['use_lstm'],\n",
    "            dropout=config['dropout']\n",
    "        )\n",
    "        model.apply(init_weights)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Define custom loss function with this config's positive weight\n",
    "        def custom_loss_fn(onset_pred, velocity_pred, onset_target, velocity_target):\n",
    "            return combined_loss_function(\n",
    "                onset_pred, velocity_pred, onset_target, velocity_target,\n",
    "                onset_weight=config['onset_weight'],\n",
    "                positive_weight=config['positive_weight']\n",
    "            )\n",
    "\n",
    "        # Train with early stopping\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=2\n",
    "        )\n",
    "\n",
    "        # Enable mixed precision training\n",
    "        scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "        best_val_f1 = 0\n",
    "        best_epoch = 0\n",
    "        early_stop_counter = 0\n",
    "\n",
    "        for epoch in range(max_epochs):\n",
    "            # Train one epoch\n",
    "            train_metrics = train_epoch(\n",
    "                model, train_loader, optimizer, device,\n",
    "                onset_weight=config['onset_weight'],\n",
    "                scaler=scaler,\n",
    "                accum_steps=1  # Smaller for grid search\n",
    "            )\n",
    "\n",
    "            # Validate with threshold optimization\n",
    "            val_metrics = validate(\n",
    "                model, val_loader, device,\n",
    "                onset_weight=config['onset_weight'],\n",
    "                positive_weight=config['positive_weight']\n",
    "            )\n",
    "\n",
    "            print(f\"Epoch {epoch+1}: F1={val_metrics['f1']:.4f} (thresh={val_metrics['threshold']:.2f}), \"\n",
    "                  f\"Train Loss={train_metrics['loss']:.4f}, Val Loss={val_metrics['loss']:.4f}\")\n",
    "\n",
    "            # Update learning rate scheduler\n",
    "            scheduler.step(val_metrics['loss'])\n",
    "\n",
    "            # Track best model\n",
    "            if val_metrics['f1'] > best_val_f1:\n",
    "                best_val_f1 = val_metrics['f1']\n",
    "                best_epoch = epoch\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "                if early_stop_counter >= 3:  # Early stopping\n",
    "                    break\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'config': config,\n",
    "            'best_f1': best_val_f1,\n",
    "            'best_epoch': best_epoch + 1\n",
    "        })\n",
    "\n",
    "        # Update overall best\n",
    "        if best_val_f1 > best_f1:\n",
    "            best_f1 = best_val_f1\n",
    "            best_config = config.copy()\n",
    "\n",
    "        # Clean up\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Sort results\n",
    "    results.sort(key=lambda x: x['best_f1'], reverse=True)\n",
    "\n",
    "    # Print top results\n",
    "    print(\"\\nTop configurations:\")\n",
    "    for i in range(min(5, len(results))):\n",
    "        res = results[i]\n",
    "        print(f\"{i+1}. F1: {res['best_f1']:.4f} at epoch {res['best_epoch']} with: {res['config']}\")\n",
    "\n",
    "    return best_config, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create larger toy datasets for grid search\n",
    "toy_train_dataset = DrumTranscriptionDataset(PROCESSED_DATA_DIR, split=\"train\", toy_mode=True, max_files=100)\n",
    "toy_val_dataset = DrumTranscriptionDataset(PROCESSED_DATA_DIR, split=\"validation\", toy_mode=True, max_files=20)\n",
    "\n",
    "# Create toy dataloaders\n",
    "toy_batch_size = 3\n",
    "toy_train_loader = DataLoader(\n",
    "    toy_train_dataset,\n",
    "    batch_size=toy_batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=1,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "toy_val_loader = DataLoader(\n",
    "    toy_val_dataset,\n",
    "    batch_size=toy_batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=1,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "# Run grid search\n",
    "best_config, all_results = grid_search_hyperparameters(\n",
    "    toy_train_loader,\n",
    "    toy_val_loader,\n",
    "    device,\n",
    "    max_epochs=15\n",
    ")\n",
    "\n",
    "print(\"\\nBest configuration found:\")\n",
    "print(f\"F1 score: {all_results[0]['best_f1']:.4f}\")\n",
    "print(best_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load and evaluate the best model ---\n",
    "print(\"\\nLoading the overall best model for evaluation...\")\n",
    "\n",
    "# Define path to the best model saved during full training\n",
    "best_model_path = MODEL_SAVE_DIR / 'drum_transcription_best.pt'\n",
    "\n",
    "if best_model_path.exists():\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(best_model_path, map_location=device)\n",
    "\n",
    "    best_model_instance = DrumTranscriptionModel(\n",
    "        n_mels=229,\n",
    "        n_drums=N_DRUMS,\n",
    "        use_lstm=best_config['use_lstm'],\n",
    "        dropout_rate=best_config['dropout_rate'],\n",
    "    )\n",
    "\n",
    "    # Load the state dict\n",
    "    best_model_instance.load_state_dict(checkpoint['model_state_dict'])\n",
    "    best_model_instance = best_model_instance.to(device)\n",
    "    best_model_instance.eval()\n",
    "\n",
    "    print(f\"Loaded best model from epoch {checkpoint.get('epoch', 'N/A')+1} with validation loss: {checkpoint.get('val_loss', 'N/A'):.4f}\")\n",
    "\n",
    "    # Validate on the test set using the best config parameters from grid search\n",
    "    # for consistency in evaluation metrics (e.g., positive_weight)\n",
    "    print(\"Validating the loaded best model on the test set...\")\n",
    "    test_metrics_loaded = validate(\n",
    "        best_model_instance,\n",
    "        test_loader,\n",
    "        device,\n",
    "        onset_weight=best_config['onset_weight'],\n",
    "        positive_weight=best_config['positive_weight']\n",
    "    )\n",
    "\n",
    "    # Print detailed metrics\n",
    "    print(f\"\\nTest Set Evaluation (Loaded Best Model, threshold={test_metrics_loaded['threshold']:.2f}):\")\n",
    "    print(f\"  Loss: {test_metrics_loaded['loss']:.4f}\")\n",
    "    print(f\"  F1 Score: {test_metrics_loaded['f1']:.4f}\")\n",
    "    print(f\"  Precision: {test_metrics_loaded['precision']:.4f}\")\n",
    "    print(f\"  Recall: {test_metrics_loaded['recall']:.4f}\")\n",
    "    print(\"\\n  Per-drum performance:\")\n",
    "    for drum_name, metrics in test_metrics_loaded['drum_metrics'].items():\n",
    "        print(f\"    {drum_name}: F1={metrics['f1']:.4f}, P={metrics['precision']:.4f}, R={metrics['recall']:.4f}\")\n",
    "\n",
    "    # Visualize predictions using the optimized threshold found during validation\n",
    "    print(\"\\nVisualizing predictions from the loaded best model...\")\n",
    "    visualize_predictions(\n",
    "        best_model_instance,\n",
    "        test_loader,\n",
    "        device,\n",
    "        threshold=test_metrics_loaded['threshold'],\n",
    "        num_samples=3\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(f\"Best model checkpoint not found at {best_model_path}. Skipping evaluation.\")\n",
    "    # Assign None or handle the case where the best model doesn't exist yet\n",
    "    best_model_instance = None\n",
    "    test_metrics_loaded = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Real Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"VRAM used: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "print(f\"VRAM free: {(12 - torch.cuda.max_memory_allocated() / 1e9):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train final model with best config\n",
    "print(\"\\nTraining final model with best configuration...\")\n",
    "final_model = DrumTranscriptionModel(\n",
    "    n_mels=229,\n",
    "    n_drums=N_DRUMS,\n",
    "    use_lstm=best_config['use_lstm'],\n",
    "    dropout=best_config['dropout']\n",
    ")\n",
    "final_model.apply(init_weights)\n",
    "final_model = final_model.to(device)\n",
    "\n",
    "# Train with best config\n",
    "final_model, _, _, _ = train_model(\n",
    "    model=final_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    learning_rate=best_config['learning_rate'],\n",
    "    epochs=30,\n",
    "    patience=7,  # More patience for final model\n",
    "    onset_weight=best_config['onset_weight'],\n",
    "    accum_steps=4,  # Can adjust based on memory\n",
    "    resume_from=None  # Start fresh\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate on Test Set\n",
    "\n",
    "Evaluate the best model on the test set to get an unbiased measure of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = MODEL_SAVE_DIR / 'drum_transcription_best.pt'\n",
    "checkpoint = torch.load(best_model_path, map_location=device)\n",
    "\n",
    "# Create a new model instance and load state\n",
    "best_model = DrumTranscriptionModel(n_mels=229, n_drums=N_DRUMS, use_lstm=True)\n",
    "best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1} with validation loss: {checkpoint['val_loss']:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics = validate(best_model, test_loader, device, onset_weight=onset_weight)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"Test Loss: {test_metrics['loss']:.4f} (Onset: {test_metrics['onset_loss']:.4f}, Velocity: {test_metrics['velocity_loss']:.4f})\")\n",
    "print(f\"F1 Score: {test_metrics['f1']:.4f}, Precision: {test_metrics['precision']:.4f}, Recall: {test_metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Predictions\n",
    "\n",
    "Let's visualize some predictions from the test set to qualitatively assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "visualize_predictions(best_model, test_loader, device, threshold=0.5, num_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've successfully built and trained a deep learning model for drum transcription. The model has dual outputs: one for detecting drum onsets (when a drum is hit) and another for predicting the velocity (how hard it's hit).\n",
    "\n",
    "**Key accomplishments:**\n",
    "\n",
    "1. Created a PyTorch dataset for loading processed training examples\n",
    "2. Designed a CNN/CRNN architecture with dual output heads\n",
    "3. Implemented a combined loss function for multi-task learning\n",
    "4. Trained the model with early stopping and learning rate scheduling\n",
    "5. Evaluated performance using appropriate metrics\n",
    "6. Visualized predictions alongside ground truth\n",
    "\n",
    "The F1 score on the test set gives us an idea of how well the model is detecting drum hits. In our next notebook, we'll explore how to convert these predictions into MIDI files and evaluate the full transcription system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drumscribe-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
