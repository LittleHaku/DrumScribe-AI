{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Feature Engineering\n",
    "\n",
    "**Objective:** Process the audio data (subset created in Notebook 1) into Mel spectrograms and extract corresponding onset/velocity targets from the MIDI files. Align these features and targets to prepare data for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pretty_midi\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.notebook import tqdm  # Use notebook version for better display\n",
    "import joblib # For saving/loading processed data\n",
    "\n",
    "# Plotting configuration\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# Define paths (adjust if necessary)\n",
    "DATA_DIR = Path('../data')\n",
    "SUBSET_METADATA_PATH = DATA_DIR / 'subset' / 'subset_metadata.csv'\n",
    "PROCESSED_DATA_DIR = DATA_DIR / 'processed'\n",
    "PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Constants (adjust as needed)\n",
    "SAMPLE_RATE = 44100\n",
    "HOP_LENGTH = 512\n",
    "N_MELS = 229 # Example value, tune as needed\n",
    "FMIN = librosa.note_to_hz('C1') # Example value\n",
    "FMAX = librosa.note_to_hz('C8') # Example value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Subset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from: ../data/subset/subset_metadata.csv\n",
      "Subset metadata loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drummer</th>\n",
       "      <th>session</th>\n",
       "      <th>id</th>\n",
       "      <th>style</th>\n",
       "      <th>bpm</th>\n",
       "      <th>beat_type</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>duration</th>\n",
       "      <th>split</th>\n",
       "      <th>midi_filename</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>kit_name</th>\n",
       "      <th>split_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/session2</td>\n",
       "      <td>drummer1/session2/80</td>\n",
       "      <td>punk</td>\n",
       "      <td>144</td>\n",
       "      <td>fill</td>\n",
       "      <td>4-4</td>\n",
       "      <td>1.661678</td>\n",
       "      <td>train</td>\n",
       "      <td>drummer1/session2/80_punk_144_fill_4-4_37.midi</td>\n",
       "      <td>drummer1/session2/80_punk_144_fill_4-4_37.wav</td>\n",
       "      <td>Live Fusion</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/session1</td>\n",
       "      <td>drummer1/session1/224</td>\n",
       "      <td>rock/halftime</td>\n",
       "      <td>140</td>\n",
       "      <td>fill</td>\n",
       "      <td>4-4</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>train</td>\n",
       "      <td>drummer1/session1/224_rock-halftime_140_fill_4...</td>\n",
       "      <td>drummer1/session1/224_rock-halftime_140_fill_4...</td>\n",
       "      <td>Funk Rock</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/session2</td>\n",
       "      <td>drummer1/session2/149</td>\n",
       "      <td>gospel</td>\n",
       "      <td>120</td>\n",
       "      <td>fill</td>\n",
       "      <td>4-4</td>\n",
       "      <td>1.853129</td>\n",
       "      <td>validation</td>\n",
       "      <td>drummer1/session2/149_gospel_120_fill_4-4_41.midi</td>\n",
       "      <td>drummer1/session2/149_gospel_120_fill_4-4_41.wav</td>\n",
       "      <td>Cassette (Lo-Fi Compress)</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/session1</td>\n",
       "      <td>drummer1/session1/260</td>\n",
       "      <td>funk/purdieshuffle</td>\n",
       "      <td>130</td>\n",
       "      <td>fill</td>\n",
       "      <td>4-4</td>\n",
       "      <td>1.846145</td>\n",
       "      <td>train</td>\n",
       "      <td>drummer1/session1/260_funk-purdieshuffle_130_f...</td>\n",
       "      <td>drummer1/session1/260_funk-purdieshuffle_130_f...</td>\n",
       "      <td>909 Simple</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/session2</td>\n",
       "      <td>drummer1/session2/198</td>\n",
       "      <td>rock</td>\n",
       "      <td>115</td>\n",
       "      <td>fill</td>\n",
       "      <td>4-4</td>\n",
       "      <td>1.726984</td>\n",
       "      <td>validation</td>\n",
       "      <td>drummer1/session2/198_rock_115_fill_4-4_24.midi</td>\n",
       "      <td>drummer1/session2/198_rock_115_fill_4-4_24.wav</td>\n",
       "      <td>Heavy Metal</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    drummer            session                     id               style  \\\n",
       "0  drummer1  drummer1/session2   drummer1/session2/80                punk   \n",
       "1  drummer1  drummer1/session1  drummer1/session1/224       rock/halftime   \n",
       "2  drummer1  drummer1/session2  drummer1/session2/149              gospel   \n",
       "3  drummer1  drummer1/session1  drummer1/session1/260  funk/purdieshuffle   \n",
       "4  drummer1  drummer1/session2  drummer1/session2/198                rock   \n",
       "\n",
       "   bpm beat_type time_signature  duration       split  \\\n",
       "0  144      fill            4-4  1.661678       train   \n",
       "1  140      fill            4-4  1.714286       train   \n",
       "2  120      fill            4-4  1.853129  validation   \n",
       "3  130      fill            4-4  1.846145       train   \n",
       "4  115      fill            4-4  1.726984  validation   \n",
       "\n",
       "                                       midi_filename  \\\n",
       "0     drummer1/session2/80_punk_144_fill_4-4_37.midi   \n",
       "1  drummer1/session1/224_rock-halftime_140_fill_4...   \n",
       "2  drummer1/session2/149_gospel_120_fill_4-4_41.midi   \n",
       "3  drummer1/session1/260_funk-purdieshuffle_130_f...   \n",
       "4    drummer1/session2/198_rock_115_fill_4-4_24.midi   \n",
       "\n",
       "                                      audio_filename  \\\n",
       "0      drummer1/session2/80_punk_144_fill_4-4_37.wav   \n",
       "1  drummer1/session1/224_rock-halftime_140_fill_4...   \n",
       "2   drummer1/session2/149_gospel_120_fill_4-4_41.wav   \n",
       "3  drummer1/session1/260_funk-purdieshuffle_130_f...   \n",
       "4     drummer1/session2/198_rock_115_fill_4-4_24.wav   \n",
       "\n",
       "                    kit_name split_set  \n",
       "0                Live Fusion     train  \n",
       "1                  Funk Rock      test  \n",
       "2  Cassette (Lo-Fi Compress)     train  \n",
       "3                 909 Simple     train  \n",
       "4                Heavy Metal      test  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the metadata DataFrame: (4554, 13)\n"
     ]
    }
   ],
   "source": [
    "# Define paths using pathlib for better cross-platform compatibility\n",
    "SUBSET_METADATA_PATH = Path('../data/subset/subset_metadata.csv')\n",
    "SUBSET_DATA_PATH = Path('../data/subset/')\n",
    "\n",
    "# Load the subset metadata CSV file\n",
    "print(f\"Loading metadata from: {SUBSET_METADATA_PATH}\")\n",
    "df_subset = pd.read_csv(SUBSET_METADATA_PATH)\n",
    "\n",
    "# Display the first few rows and the shape to verify loading\n",
    "print(\"Subset metadata loaded successfully.\")\n",
    "display(df_subset.head())\n",
    "print(f\"Shape of the metadata DataFrame: {df_subset.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Audio Preprocessing (Resampling, Normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Define Parameters\n",
    "\n",
    "We define the target sample rate we want to convert all audio files to. This ensures consistency for the model input. A common choice for audio ML tasks is 22050 Hz, as it captures most relevant frequencies while reducing computational load compared to 44100 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Sample Rate: 22050 Hz\n"
     ]
    }
   ],
   "source": [
    "TARGET_SR: int = 22050\n",
    "print(f\"Target Sample Rate: {TARGET_SR} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Preprocessing Function\n",
    "\n",
    "We define a function to handle the core preprocessing steps:\n",
    "\n",
    "1.  **Loading & Resampling:** Load the audio file using `librosa.load`. We specify `sr=TARGET_SR` to resample the audio to our target rate during loading. We also set `mono=True` to convert the audio to mono, as stereo information is often not critical for drum transcription and simplifies the input.\n",
    "2.  **Normalization:** Perform peak normalization by dividing the audio signal by its maximum absolute value. This scales the audio to the range [-1, 1], preventing issues caused by varying loudness levels across different recordings. We add a small epsilon (`1e-8`) to the denominator to avoid division by zero in case of silent audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def preprocess_audio(audio_path: Path, target_sr: int) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Loads, resamples, and normalizes an audio file.\n",
    "\n",
    "    Args:\n",
    "        audio_path (Path): Path to the input audio file.\n",
    "        target_sr (int): The target sample rate to resample to.\n",
    "\n",
    "    Returns:\n",
    "        Optional[np.ndarray]: The preprocessed audio as a NumPy array,\n",
    "                               or None if loading fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio, resample to target_sr, convert to mono\n",
    "        audio, sr = librosa.load(audio_path, sr=target_sr, mono=True)\n",
    "\n",
    "        # Peak normalization\n",
    "        max_abs_val = np.max(np.abs(audio))\n",
    "        if max_abs_val > 0:\n",
    "            audio_normalized = audio / (max_abs_val + 1e-8) # Add epsilon for stability\n",
    "        else:\n",
    "            audio_normalized = audio # Avoid division by zero for silence\n",
    "\n",
    "        return audio_normalized\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Demonstrate on an Example\n",
    "\n",
    "Let's apply the preprocessing function to one example audio file from our subset and compare it to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected path (v2) to load: ../data/subset/train/drummer1/session2/80_punk_144_fill_4-4_37.wav\n",
      "Current Working Directory: /home/ivan/uni/APPSA/DrumScribe-AI/notebooks\n",
      "SUBSET_DATA_PATH: ../data/subset\n",
      "Using row index: 0\n",
      "row['split_set']: train\n",
      "row['audio_filename']: drummer1/session2/80_punk_144_fill_4-4_37.wav\n",
      "Constructed Path: ../data/subset/train/drummer1/session2/80_punk_144_fill_4-4_37.wav\n",
      "Path Type: <class 'pathlib.PosixPath'>\n",
      "Does Path Exist? False\n",
      "Is it a File? False\n",
      "Attempting to load: ../data/subset/train/drummer1/session2/80_punk_144_fill_4-4_37.wav\n",
      "Error loading original audio ../data/subset/train/drummer1/session2/80_punk_144_fill_4-4_37.wav: [Errno 2] No such file or directory: '../data/subset/train/drummer1/session2/80_punk_144_fill_4-4_37.wav'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64509/2618242519.py:30: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  original_audio, original_sr = librosa.load(original_full_path, sr=None, mono=True)\n",
      "/home/ivan/.pyenv/versions/3.11.11/envs/drumscribe-ai/lib/python3.11/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "# Select the first audio file from the subset metadata\n",
    "example_row = df_subset.iloc[0]\n",
    "# Construct the correct full path using split_set and audio_filename\n",
    "original_full_path = (\n",
    "    SUBSET_DATA_PATH /\n",
    "    example_row['split_set'] /\n",
    "    example_row['audio_filename'] # This column already has drummer/session/filename\n",
    ")\n",
    "print(f\"Corrected path (v2) to load: {original_full_path}\") # Add print for verification\n",
    "\n",
    "# --- Load Original Audio ---\n",
    "try:\n",
    "    # --- Debugging Path ---\"\n",
    "    print(f\"Current Working Directory: {Path.cwd()}\")\n",
    "    print(f\"SUBSET_DATA_PATH: {SUBSET_DATA_PATH}\")\n",
    "    print(f\"Using row index: {example_row.name}\") # Assuming example_row is a Series from df_subset.iloc[X]\n",
    "    print(f\"row['split_set']: {example_row['split_set']}\")\n",
    "    print(f\"row['audio_filename']: {example_row['audio_filename']}\")\n",
    "    # Construct the path again for clarity in debug output\n",
    "    constructed_path = SUBSET_DATA_PATH / example_row['split_set'] / example_row['audio_filename']\n",
    "    print(f\"Constructed Path: {constructed_path}\")\n",
    "    print(f\"Path Type: {type(constructed_path)}\")\n",
    "    print(f\"Does Path Exist? {constructed_path.exists()}\")\n",
    "    print(f\"Is it a File? {constructed_path.is_file()}\")\n",
    "    # --- End Debugging Path ---\n",
    "\n",
    "    # Ensure the path used in librosa.load is the same one checked\n",
    "    original_full_path = constructed_path\n",
    "    print(f\"Attempting to load: {original_full_path}\") # Keep this print\n",
    "    original_audio, original_sr = librosa.load(original_full_path, sr=None, mono=True)\n",
    "    print(f\"Original Audio: Sample Rate = {original_sr} Hz, Duration = {len(original_audio)/original_sr:.2f}s\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading original audio {original_full_path}: {e}\")\n",
    "    original_audio, original_sr = None, None\n",
    "\n",
    "# --- Preprocess Audio ---\n",
    "if original_audio is not None:\n",
    "    preprocessed_audio = preprocess_audio(original_full_path, TARGET_SR)\n",
    "    if preprocessed_audio is not None:\n",
    "        print(f\"Preprocessed Audio: Sample Rate = {TARGET_SR} Hz, Duration = {len(preprocessed_audio)/TARGET_SR:.2f}s, Range = [{preprocessed_audio.min():.2f}, {preprocessed_audio.max():.2f}]\")\n",
    "    else:\n",
    "        print(\"Preprocessing failed for the example file.\")\n",
    "else:\n",
    "    preprocessed_audio = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Visualize Comparison\n",
    "\n",
    "Now, let's visualize the waveforms of the original and preprocessed audio signals side-by-side.\n",
    "\n",
    "*   **Original Waveform:** Shows the audio signal as loaded from the file, with its original sample rate and amplitude range.\n",
    "*   **Preprocessed Waveform:** Shows the audio signal after resampling to `TARGET_SR` and peak normalization. Notice the change in the time axis scale due to resampling and the amplitude axis scale due to normalization (now within [-1, 1])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot visualize comparison due to loading/processing errors.\n"
     ]
    }
   ],
   "source": [
    "if original_audio is not None and preprocessed_audio is not None:\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # Plot Original Waveform\n",
    "    plt.subplot(2, 1, 1)\n",
    "    librosa.display.waveshow(original_audio, sr=original_sr, alpha=0.8)\n",
    "    plt.title(f'Original Waveform (Sample Rate: {original_sr} Hz)')\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.ylim([-1, 1]) # Set consistent y-lim for comparison, though original might exceed it\n",
    "\n",
    "    # Plot Preprocessed Waveform\n",
    "    plt.subplot(2, 1, 2)\n",
    "    librosa.display.waveshow(preprocessed_audio, sr=TARGET_SR, alpha=0.8, color='r')\n",
    "    plt.title(f'Preprocessed Waveform (Sample Rate: {TARGET_SR} Hz, Normalized)')\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.ylim([-1.1, 1.1]) # Normalized range is [-1, 1]\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot visualize comparison due to loading/processing errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mel Spectrogram Extraction & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for Mel spectrogram extraction using librosa\n",
    "# Define function to compute log-Mel spectrogram\n",
    "# Visualize an example spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MIDI Feature Extraction (Onsets, Velocities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for loading MIDI files using pretty_midi\n",
    "# Extract drum note onsets and velocities\n",
    "# Define function for MIDI processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Align Audio Features and MIDI Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for aligning spectrogram frames with MIDI events\n",
    "# Convert MIDI onsets/velocities into frame-wise targets\n",
    "# Handle timing differences and frame alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create and Save Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for combining features and targets into structured examples\n",
    "# Decide on data format (e.g., numpy arrays, dictionaries)\n",
    "# Save processed examples (e.g., using joblib or numpy.savez)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. (Optional) Data Pipeline Ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for brainstorming efficient data loading strategies for training\n",
    "# Consider PyTorch Datasets/DataLoaders, tf.data, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drumscribe-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
